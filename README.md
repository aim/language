# aim

- https://astexplorer.net/
- lexemes (patterns) -> lexer/scanner -> tokens -> parser -> ast
- lexeme = Sequence of characters matched by PATTERN forming the TOKEN
- pattern = The set of rule that define a TOKEN
- tokens = The meaningful collection of characters over the character set of the programming language ex:ID, Constant, Keywords, Operators, Punctuation, Literal String
- In computer science, scannerless parsing (also called lexerless parsing) performs tokenization (breaking a stream of characters into words) and parsing (arranging the words into phrases) in a single step, rather than breaking it up into a pipeline of a lexer followed by a parser, executing concurrently. A language grammar is scannerless if it uses a single formalism to express both the lexical (word level) and phrase level structure of the language.

